% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/http.R
\name{TWIT_paginate_max_id}
\alias{TWIT_paginate_max_id}
\alias{TWIT_paginate_cursor}
\alias{TWIT_paginate_chunked}
\title{Pagination}
\usage{
TWIT_paginate_max_id(
  token,
  api,
  params,
  get_id = function(x) x$id_str,
  n = 1000,
  page_size = 200,
  parse = TRUE,
  since_id = NULL,
  max_id = NULL,
  count_param = "count",
  retryonratelimit = FALSE,
  verbose = TRUE
)

TWIT_paginate_cursor(
  token,
  api,
  params,
  n = 5000,
  page_size = 5000,
  cursor = "-1",
  get_id = function(x) x$ids,
  retryonratelimit = FALSE,
  verbose = TRUE
)

TWIT_paginate_chunked(
  token,
  api,
  params_list,
  retryonratelimit = FALSE,
  verbose = TRUE
)
}
\arguments{
\item{token}{Expert use only. Use this to override authentication for
a single API call. In most cases you are better off changing the
default for all calls. See \code{\link[=auth_as]{auth_as()}} for details.}

\item{get_id}{A single argument function that returns a vector of ids given
the JSON response. The defaults are chosen to cover the most common cases,
but you'll need to double check whenever implementing pagination for
a new endpoint.}

\item{n}{Maximum number of results to return.}

\item{parse}{The default, \code{TRUE}, indicates that the result should
be parsed into a convenient R data structure like a list or data frame.
This protects you from the vagaries of the twitter API. Use \code{FALSE}
to return the "raw" list produced by the JSON returned from the twitter
API.}

\item{since_id}{Provides a lower-bound for the results returned; all results
will have an ID greater than or equal to \code{since_id}. This can generally
be omitted.}

\item{max_id}{Provide an upper bound for the returned results; all results
will have an ID less than or equal to \code{max_id}. If omitted, results will
start from the most recent available. Supplying \code{max_id} allows you to
manually paginate the results.}

\item{retryonratelimit}{If \code{TRUE}, and a rate limit is exhausted, will wait
until it refreshes. Most twitter rate limits refresh every 15 minutes.
If \code{FALSE}, and the rate limit is exceeded, the function will terminate
early with a warning; you'll still get back all results received up to
that point.

If you expect a query to take hours or days to perform, you should not
rely soley on \code{retryonratelimit} because it does not handle other common
failure modes like temporarily losing your internet connection.}

\item{verbose}{Show progress bars and other messages indicating current
progress?}

\item{cursor}{Which page of results to return. The default will return
the first page; can be used for manual pagination.}
}
\description{
\ifelse{html}{\href{https://lifecycle.r-lib.org/articles/stages.html#experimental}{\figure{lifecycle-experimental.svg}{options: alt='[Experimental]'}}}{\strong{[Experimental]}}
These are internal functions used for pagination inside of rtweet.
}
\keyword{internal}
